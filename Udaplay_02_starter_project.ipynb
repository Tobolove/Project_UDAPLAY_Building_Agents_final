{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# [STARTER] Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a963d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import the necessary libs\n",
    "# For example: \n",
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.api.models.Collection import Collection\n",
    "\n",
    "from lib.agents import Agent, AgentState\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage\n",
    "from lib.tooling import tool\n",
    "from dotenv import load_dotenv\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination, Resource\n",
    "from typing import TypedDict, List\n",
    "\n",
    "from lib.evaluation import TestCase, AgentEvaluator, EvaluationResult\n",
    "from lib.state_machine import Run\n",
    "import time\n",
    "from typing import List, Dict\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from datetime import datetime\n",
    "from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Load environment variables\n",
    "# load_dotenv()\n",
    "\n",
    "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "# all variables are loaded from .env file in gitignore i used my private keys\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create retrieve_game tool\n",
    "# It should use chroma client and collection you created\n",
    "chroma_client = chromadb.PersistentClient(path=\"chromadb\")      \n",
    "\n",
    "# Use the same embedding function \n",
    "embedding_fn = embedding_functions.OpenAIEmbeddingFunction()\n",
    "collection = chroma_client.get_collection(\"udaplay\", embedding_function=embedding_fn)\n",
    "\n",
    "@tool\n",
    "def retrieve_game(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Semantic search: Finds most results in the vector DB\n",
    "    args:\n",
    "    - query: a question about game industry. \n",
    "\n",
    "    You'll receive results as list. Each element contains:\n",
    "    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "    - Name: Name of the Game\n",
    "    - YearOfRelease: Year when that game was released for that platform\n",
    "    - Description: Additional details about the game\n",
    "    \"\"\"\n",
    "    # Search the collection for relevant games\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=5  # Get top 5 most relevant results\n",
    "    )\n",
    "    \n",
    "    # Format the results for \n",
    "    if not results['documents'][0]:\n",
    "        return \"No games found matching your query.\"\n",
    "    \n",
    "    formatted_results = []\n",
    "    for i in range(len(results['documents'][0])):\n",
    "        metadata = results['metadatas'][0][i]\n",
    "        document = results['documents'][0][i]\n",
    "        \n",
    "        game_info = {\n",
    "            \"Platform\": metadata.get(\"Platform\", \"Unknown\"),\n",
    "            \"Name\": metadata.get(\"Name\", \"Unknown\"),\n",
    "            \"YearOfRelease\": metadata.get(\"YearOfRelease\", \"Unknown\"),\n",
    "            \"Description\": metadata.get(\"Description\", \"No description available\"),\n",
    "            \"Genre\": metadata.get(\"Genre\", \"Unknown\"),\n",
    "            \"Publisher\": metadata.get(\"Publisher\", \"Unknown\")\n",
    "        }\n",
    "        formatted_results.append(game_info)\n",
    "    \n",
    "    return str(formatted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a58d6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing retrieve_game tool with query: which games have a racing characrer?\n",
      "==================================================\n",
      "[{'Platform': 'PlayStation 3', 'Name': 'Gran Turismo 5', 'YearOfRelease': 2010, 'Description': 'A comprehensive racing simulator featuring a vast selection of vehicles and tracks, with realistic driving physics.', 'Genre': 'Racing', 'Publisher': 'Sony Computer Entertainment'}, {'Platform': 'PlayStation 1', 'Name': 'Gran Turismo', 'YearOfRelease': 1997, 'Description': 'A realistic racing simulator featuring a wide array of cars and tracks, setting a new standard for the genre.', 'Genre': 'Racing', 'Publisher': 'Sony Computer Entertainment'}, {'Platform': 'Nintendo Switch', 'Name': 'Mario Kart 8 Deluxe', 'YearOfRelease': 2017, 'Description': 'An enhanced version of Mario Kart 8, featuring new characters, tracks, and improved gameplay mechanics.', 'Genre': 'Racing', 'Publisher': 'Nintendo'}, {'Platform': 'Nintendo 64', 'Name': 'Super Mario 64', 'YearOfRelease': 1996, 'Description': \"A groundbreaking 3D platformer that set new standards for the genre, featuring Mario's quest to rescue Princess Peach.\", 'Genre': 'Platformer', 'Publisher': 'Nintendo'}, {'Platform': 'PlayStation 2', 'Name': 'Grand Theft Auto: San Andreas', 'YearOfRelease': 2004, 'Description': \"An expansive open-world game set in the fictional state of San Andreas, following the story of Carl 'CJ' Johnson.\", 'Genre': 'Action-adventure', 'Publisher': 'Rockstar Games'}]\n"
     ]
    }
   ],
   "source": [
    "# Test the retrieve_game tool (ADDITONAL TEST SCRIPT) Works!\n",
    "test_query = \"which games have a racing characrer?\"\n",
    "print(\"Testing retrieve_game tool with query:\", test_query)\n",
    "print(\"=\" * 50)\n",
    "\n",
    "result = retrieve_game(test_query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1697f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ADDITIONAL TEST SCRIPT) Works!  used the evaluator to test the agents output!\n",
    "agent = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    tools=[retrieve_game],\n",
    "    instructions=\"You can bring insights about a game dataset based on users questions\",\n",
    ")\n",
    "\n",
    "evaluator = AgentEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e568c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Test Case: game_query_1 ===\n",
      "Description: FInd a game with a racing character\n",
      "Query: I am interested in games with a racing character, do you know any?\n",
      "\n",
      "Workflow:\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "\n",
      "--- Black Box (Final Response) Evaluation ---\n",
      "Overall Score: 1.00\n",
      "Task Completed: True\n",
      "Feedback: The agent successfully provided a list of games that feature a racing character, which directly answers the user's query. The format is clear and organized, listing the games with relevant details such as platform, year of release, and description. Additionally, the agent followed the implicit instruction to provide multiple examples and offered to assist further if the user has specific preferences, demonstrating attentiveness to the user's needs.\n",
      "\n",
      "--- Single Step Evaluation ---\n",
      "Overall Score: 1.00\n",
      "Correct Tool Selected: True\n",
      "Feedback: Selected tools: ['retrieve_game'], Expected: ['retrieve_game']\n",
      "\n",
      "--- Trajectory Evaluation ---\n",
      "Overall Score: 1.00\n",
      "Steps Taken: 4\n",
      "Total Tokens: 877\n",
      "Execution Time: 6.77s\n",
      "Estimated Cost: $0.000329\n",
      "Feedback: Trajectory: 4 steps, Tools used: ['retrieve_game'], Expected: ['retrieve_game']\n"
     ]
    }
   ],
   "source": [
    "# (ADDITIONAL TEST SCRIPT) Works!  used the evaluator to test the agents output!\n",
    "test_cases = [\n",
    "    TestCase(\n",
    "        id=\"game_query_1\",\n",
    "        description=\"FInd a game with a racing character\",\n",
    "        user_query=\"I am interested in games with a racing character, do you know any?\",\n",
    "        expected_tools=[\"retrieve_game\"],\n",
    "        reference_answer=\"Gran Turismo 5\",\n",
    "        max_steps=4\n",
    "    ),\n",
    "]\n",
    "\n",
    "for test_case in test_cases:\n",
    "    print(f\"\\n=== Evaluating Test Case: {test_case.id} ===\")\n",
    "    print(f\"Description: {test_case.description}\")\n",
    "    print(f\"Query: {test_case.user_query}\")\n",
    "    \n",
    "    # Run the agent\n",
    "    start_time = time.time()\n",
    "    print(\"\\nWorkflow:\")\n",
    "    agent.memory.reset()\n",
    "    run_object:Run = agent.invoke(test_case.user_query)\n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    # Get final state and response\n",
    "    final_state:AgentState = run_object.get_final_state()\n",
    "    if final_state and final_state.get(\"messages\"):\n",
    "        # Find the last AI message as the final response\n",
    "        final_response = \"\"\n",
    "        for msg in reversed(final_state[\"messages\"]):\n",
    "            if isinstance(msg, AIMessage) and msg.content:\n",
    "                final_response = msg.content\n",
    "                break\n",
    "        \n",
    "        total_tokens = final_state.get(\"total_tokens\", 0)\n",
    "        \n",
    "        # Evaluate using all three methods\n",
    "        print(\"\\n--- Black Box (Final Response) Evaluation ---\")\n",
    "        black_box_eval:EvaluationResult = evaluator.evaluate_final_response(\n",
    "            test_case, final_response, execution_time, total_tokens\n",
    "        )\n",
    "        print(f\"Overall Score: {black_box_eval.overall_score:.2f}\")\n",
    "        print(f\"Task Completed: {black_box_eval.task_completion.task_completed}\")\n",
    "        print(f\"Feedback: {black_box_eval.feedback}\")\n",
    "        \n",
    "        print(\"\\n--- Single Step Evaluation ---\")\n",
    "        step_eval:EvaluationResult = evaluator.evaluate_single_step(\n",
    "            final_state[\"messages\"], test_case.expected_tools\n",
    "        )\n",
    "        print(f\"Overall Score: {step_eval.overall_score:.2f}\")\n",
    "        print(f\"Correct Tool Selected: {step_eval.tool_interaction.correct_tool_selected}\")\n",
    "        print(f\"Feedback: {step_eval.feedback}\")\n",
    "        \n",
    "        print(\"\\n--- Trajectory Evaluation ---\")\n",
    "        traj_eval:EvaluationResult = evaluator.evaluate_trajectory(test_case, run_object)\n",
    "        print(f\"Overall Score: {traj_eval.overall_score:.2f}\")\n",
    "        print(f\"Steps Taken: {traj_eval.task_completion.steps_taken}\")\n",
    "        print(f\"Total Tokens: {traj_eval.system_metrics.total_tokens}\")\n",
    "        print(f\"Execution Time: {traj_eval.system_metrics.execution_time:.2f}s\")\n",
    "        print(f\"Estimated Cost: ${traj_eval.system_metrics.cost_estimate:.6f}\")\n",
    "        print(f\"Feedback: {traj_eval.feedback}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"ERROR: No final state or messages found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "Useful: True\n",
      "Description: The retrieved documents contain relevant information that directly addresses the user's query about recommending a racing game. Specifically, there are three racing games listed: 'Gran Turismo 5' (2010), 'Gran Turismo' (1997), and 'Mario Kart 8 Deluxe' (2017). Each entry includes the platform, name, year of release, description, genre, and publisher, which provides a comprehensive overview of each game. The information is sufficient to recommend these titles to the user. However, there is a minor gap in that the documents do not provide a comparative analysis or personal recommendations based on user preferences, but they still adequately fulfill the basic requirement of suggesting racing games. Overall, the quality of information is sufficient for the purpose of answering the user's question.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create evaluate_retrieval tool\n",
    "class EvaluationReport(BaseModel):\n",
    "    \"\"\"Evaluation report for document retrieval quality\"\"\"\n",
    "    useful: bool\n",
    "    description: str\n",
    "\n",
    "# Create LLM instance for evaluation\n",
    "evaluator_llm = LLM(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "@tool\n",
    "def evaluate_retrieval(question: str, retrieved_docs: str) -> str:\n",
    "    \"\"\"\n",
    "    Based on the user's question and on the list of retrieved documents, \n",
    "    it will analyze the usability of the documents to respond to that question. \n",
    "    args: \n",
    "    - question: original question from user\n",
    "    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "    The result includes:\n",
    "    - useful: whether the documents are useful to answer the question\n",
    "    - description: description about the evaluation result\n",
    "    \"\"\"\n",
    "    \n",
    "    # System message for the LLM judge\n",
    "    system_message = \"\"\"You are a strict document evaluator you only evaluate NOT MAKE ANY INTERPRETATIONS. Your task is to evaluate if the documents are enough to can respond to the users query accurately.\n",
    "\n",
    "Be very strict here in the following in your evaluation\n",
    "1. Do the documents contain the information needed to answer the question fully?\n",
    "2. Is the information relevant and directly usefull?\n",
    "3. Are there any informations gaps that would prevent a complete answer?\n",
    "4. Is the quality of information sufficient?\n",
    "\n",
    "Provide a detailed explanation so it's possible to take an action to accept the documents or search for additional information.\"\"\"\n",
    "\n",
    "    # User prompt for evaluation\n",
    "    user_prompt = f\"\"\"\n",
    "Question: {question}\n",
    "\n",
    "Retrieved Documents: {retrieved_docs}\n",
    "\n",
    "Please evaluate these retrieved documents are sufficient to answer the user question.\n",
    "\n",
    "Return your evaluation in the following JSON format:\n",
    "{{\n",
    "    \"useful\": true/false,\n",
    "    \"description\": \"detailed explanation of your evaluation, including what information is present, what might be missing, and whether the documents can adequately answer the question\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        # Create messages for the LLM\n",
    "        messages = [\n",
    "            SystemMessage(content=system_message),\n",
    "            UserMessage(content=user_prompt)\n",
    "        ]\n",
    "        \n",
    "        # Get evaluation from LLM\n",
    "        response = evaluator_llm.invoke(messages)\n",
    "        \n",
    "        # Try to parse as JSON and validate with Pydantic\n",
    "        import json\n",
    "        try:\n",
    "            result_dict = json.loads(response.content)\n",
    "            evaluation_report = EvaluationReport(**result_dict)\n",
    "            return f\"Useful: {evaluation_report.useful}\\nDescription: {evaluation_report.description}\"\n",
    "        except (json.JSONDecodeError, ValueError) as e:\n",
    "            # If parsing fails, return the raw response\n",
    "            return f\"parsing failed. Raw response: {response.content}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error during evaluation: {str(e)}\"\n",
    "\n",
    "\n",
    "# Test the tool (ADDITIONAL TEST SCRIPT) Works!\n",
    "if __name__ == \"__main__\":\n",
    "    # Example test\n",
    "    test_question = \"Can you recommend a racing?\"\n",
    "    test_docs = \"\"\"[{'Platform': 'PlayStation 3', 'Name': 'Gran Turismo 5', 'YearOfRelease': 2010, 'Description': 'A comprehensive racing simulator featuring a vast selection of vehicles and tracks, with realistic driving physics.', 'Genre': 'Racing', 'Publisher': 'Sony Computer Entertainment'}, {'Platform': 'PlayStation 1', 'Name': 'Gran Turismo', 'YearOfRelease': 1997, 'Description': 'A realistic racing simulator featuring a wide array of cars and tracks, setting a new standard for the genre.', 'Genre': 'Racing', 'Publisher': 'Sony Computer Entertainment'}, {'Platform': 'Nintendo Switch', 'Name': 'Mario Kart 8 Deluxe', 'YearOfRelease': 2017, 'Description': 'An enhanced version of Mario Kart 8, featuring new characters, tracks, and improved gameplay mechanics.', 'Genre': 'Racing', 'Publisher': 'Nintendo'}, {'Platform': 'Nintendo 64', 'Name': 'Super Mario 64', 'YearOfRelease': 1996, 'Description': \"A groundbreaking 3D platformer that set new standards for the genre, featuring Mario's quest to rescue Princess Peach.\", 'Genre': 'Platformer', 'Publisher': 'Nintendo'}, {'Platform': 'PlayStation 2', 'Name': 'Grand Theft Auto: San Andreas', 'YearOfRelease': 2004, 'Description': \"An expansive open-world game set in the fictional state of San Andreas, following the story of Carl 'CJ' Johnson.\", 'Genre': 'Action-adventure', 'Publisher': 'Rockstar Games'}]\"\"\"\n",
    "    \n",
    "    result = evaluate_retrieval(test_question, test_docs)\n",
    "    print(\"Test Result:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create game_web_search tool\n",
    "# INVOKE the Tavily client to search the web\n",
    "api_key_tavily = os.getenv(\"TAVILY_API_KEY\")\n",
    "client = TavilyClient(api_key=api_key_tavily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04a07aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Which game everyone is waiting for in 2025?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.reddit.com/r/gaming/comments/1hw0e7x/which_2025_game_are_you_most_looking_forward_to/',\n",
       "   'title': 'Which 2025 game are you most looking forward to? - Reddit',\n",
       "   'content': \"Either Doom: The Dark Ages or Metal Gear Solid Delta for me personally. I'm not saying GTA 6 as I think it will probably get delayed.\",\n",
       "   'score': 0.8351749,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.gamesradar.com/video-game-release-dates/',\n",
       "   'title': 'New games 2025 release schedule | GamesRadar+',\n",
       "   'content': \"Subscribe from just £3 Takes you closer to the games, movies and TV you love Try a single issue or save on a subscription Issues delivered straight to your door or device From$12 View Trending GTA 6 trailer 2 Upcoming Switch 2 games FGS Live Latam The Duskbloods Games New games 2025 and beyond: The biggest video game release dates for PS5, Xbox Series X, PC, Switch, and more Features By Emma-Jane Betts, Josh West Contributions from Sam Loveridge, Jasmine Gould-Wilson, Heather Wald last updated May 2, 2025 Here's all the new games and release dates of 2025 to help you catch up or plan ahead for May and beyond, from Doom: The Dark Ages to Borderlands 4 Comments ( 0 ) () When you purchase through links on our site, we may earn an affiliate commission. (Image credit: EA/Kojima Productions/Capcom/Xbox) Jump to: January February March April May June July August September October TBC 2025 2026 TBC 2026 TBC Keeping track of all the new games of 2025 is a massive undertaking, but it is also well worth it. Looking further ahead, there's also plenty of exciting new games for the rest of the year, with the likes of Borderlands 4, and the release of Nintendo's new Switch 2 console (and a slew of upcoming Switch 2 games), even if GTA 6 has moved to 2026. We're here to help you keep track of all the upcoming Xbox Series X games, upcoming PS5 games, upcoming PC games, and upcoming Switch games in the pipeline.\",\n",
       "   'score': 0.8047902,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.ign.com/playlist/tkwarner/lists/most-anticipated-new-games',\n",
       "   'title': 'Most Anticipated Announced Games (2025-) - an IGN Playlist by ...',\n",
       "   'content': 'Metal Gear Solid Δ: Snake Eater. KCEJ ; Shinobi: Art of Vengeance. SEGA ; Crimson Desert. Pearl Abyss ; Cronos: The New Dawn. Bloober Team ; Resident Evil: Requiem.',\n",
       "   'score': 0.77913743,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.esquire.com/entertainment/a63435905/best-video-games-2025/',\n",
       "   'title': 'The Best Video Games of 2025 (So Far) - Esquire',\n",
       "   'content': 'Image 1 Image 8 Image 46: mario kart world ‘Mario Kart World’ Made Me Feel Like a Kid AgainImage 47: a gaming headset The 6 Best Headsets for Serious GamersImage 48: e 38 Actually Good Gifts for GamersImage 49: nintendo switch 2 I Tested the Nintendo Switch 2. Image 54: illustration featuring a superhero and characters in a dynamic interaction The 20 Best Multiplayer PlayStation Games in 2025Image 55: a handheld gaming system Finally, a Good Alternative to the Nintendo SwitchImage 56: virtual reality headset with controllers Meta Quest 3S Review 2025Image 57: handheld gaming console with detachable controllers on either side Here’s What You Need to Know About the Switch 2',\n",
       "   'score': 0.62358373,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.gamespot.com/articles/2025-upcoming-games-release-schedule/1100-6526471/',\n",
       "   'title': '2025 Upcoming Games Release Schedule - GameSpot',\n",
       "   'content': 'GameSpot has broken down all the games planned for release in 2025. This includes games that have concrete dates, as well as those given a 2025 release window.',\n",
       "   'score': 0.38755178,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.87}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the Tavily client with a search query\n",
    "result = client.search(\"Which game everyone is waiting for in 2025?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "992ff75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Craete the web_search tool to use for agents\n",
    "@tool\n",
    "def web_search(query: str, search_depth: str = \"advanced\") -> Dict:\n",
    "    \"\"\"\n",
    "    Search the web using Tavily API\n",
    "    \n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "    client = TavilyClient(api_key=api_key)\n",
    "    \n",
    "    # Perform the search\n",
    "    search_result = client.search(\n",
    "        query=query,\n",
    "        search_depth=search_depth,\n",
    "        include_answer=True,\n",
    "        include_raw_content=False,\n",
    "        include_images=False\n",
    "    )\n",
    "    \n",
    "    # Format the results\n",
    "    formatted_results = {\n",
    "        \"answer\": search_result.get(\"answer\", \"\"),\n",
    "        \"results\": search_result.get(\"results\", []),\n",
    "        \"search_metadata\": {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"query\": query\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "887c8523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the list for the tools\n",
    "tools = [web_search, retrieve_game, evaluate_retrieval]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31c56281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your Agent abstraction using StateMachine\n",
    "\n",
    "#Solutions as an agent!\n",
    "\n",
    "game_advisor_agent = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    instructions=(\n",
    "            \"You are a game advisor agent. Your task is to provide insights about games based on user questions. \"\n",
    "            \"You can use the tools provided to search the web, retrieve game information, and evaluate the quality of your responses. \"\n",
    "            \"Make sure to use the tools effectively to gather information and provide accurate answers. \"\n",
    "            \"Always start with searching your own database for relevant games, and if necessary, use the web search if the evaluation tool indicates that the retrieved documents are not sufficient. \"\n",
    "    ),\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231c31b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "Agent Reasoning & Tool Usage:\n",
      "Using tool: retrieve_game\n",
      "Arguments: {\"query\":\"Pokémon Gold and Silver release date\"}\n",
      "Tool result: \"[{'Platform': 'Game Boy Color', 'Name': 'Pok\\u00e9mon Gold and Silver', 'YearOfRelease': 1999, 'Des...\n",
      "Final Answer:\n",
      "Pokémon Gold and Silver were released for the Game Boy Color in 1999. These games are known as the second generation of Pokémon games, introducing new regions, Pokémon, and gameplay mechanics.\n",
      "Tools used: retrieve_game\n"
     ]
    }
   ],
   "source": [
    "# Test script for one usecase.\n",
    "\n",
    "# delete memory as it is session based\n",
    "game_advisor_agent.memory.reset()\n",
    "# 1. Ask your question\n",
    "result = game_advisor_agent.invoke(\"When were Pokémon Gold and Silver released?\")\n",
    "# 2. Get the answer with reasoning and tool usage\n",
    "final_state = result.get_final_state()\n",
    "\n",
    "# Show agent reasoning and tool usage\n",
    "print(\"Agent Reasoning & Tool Usage:\")\n",
    "messages = final_state.get(\"messages\", [])\n",
    "tools_used = []\n",
    "\n",
    "for msg in messages:\n",
    "    if isinstance(msg, AIMessage) and hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "        for tool_call in msg.tool_calls:\n",
    "            tool_name = tool_call.function.name\n",
    "            tools_used.append(tool_name)\n",
    "            print(f\"Using tool: {tool_name}\")\n",
    "            print(f\"Arguments: {tool_call.function.arguments}\")\n",
    "    elif isinstance(msg, ToolMessage):\n",
    "        result_preview = msg.content[:100] + \"...\" if len(msg.content) > 100 else msg.content\n",
    "        print(f\"Tool result: {result_preview}\")\n",
    "\n",
    "# Show final answer\n",
    "print(\"Final Answer:\")\n",
    "final_answer_found = False\n",
    "for msg in reversed(final_state[\"messages\"]):\n",
    "    if isinstance(msg, AIMessage) and msg.content:\n",
    "        # Check if this is a final answer (not a tool call message)\n",
    "        if not hasattr(msg, 'tool_calls') or not msg.tool_calls:\n",
    "            print(msg.content)\n",
    "            final_answer_found = True\n",
    "            break\n",
    "\n",
    "if not final_answer_found:\n",
    "    print(\"No final answer found in messages\")\n",
    "\n",
    "print(f\"Tools used: {', '.join(set(tools_used)) if tools_used else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ StateMachine created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Solution AS a complete workflow, StateMachine that will use the tools and Agent in a workflow for more controll!! (i like this more as it is less error aprun)\n",
    "class GameResearchState(TypedDict):\n",
    "    user_query: str\n",
    "    retrieved_docs: str\n",
    "    evaluation_result: str\n",
    "    web_search_result: str\n",
    "    final_answer: str\n",
    "    confidence_score: float\n",
    "    sources_used: List[str]\n",
    "\n",
    "\n",
    "def query_vector_db(state: GameResearchState) -> Dict:\n",
    "    \"\"\"Step 1: Ask the vector database for relevant games\"\"\"\n",
    "    print(\"Searcing my database for information about the question :)\")\n",
    "    \n",
    "    retrieved_docs = retrieve_game(state[\"user_query\"])\n",
    "    sources_used = state.get(\"sources_used\", []) + [\"vector_database\"]\n",
    "    \n",
    "    print(f\"Found documents\")\n",
    "    return {\n",
    "        \"retrieved_docs\": retrieved_docs,\n",
    "        \"sources_used\": sources_used\n",
    "    }\n",
    "\n",
    "def evaluate_documents(state: GameResearchState) -> Dict:\n",
    "    \"\"\"Step 2: Evaluate if retrieved documents are sufficient\"\"\"\n",
    "    print(\" EValuating the quality of the answer from the db. Hope its GOOD\")\n",
    "    \n",
    "    if state[\"retrieved_docs\"] == \"No games found matching your query.\":\n",
    "        evaluation_result = \"Useful: False\\nDescription: No documents were retrieved from the vector database.\"\n",
    "        confidence_score = 0.0\n",
    "    else:\n",
    "        evaluation_result = evaluate_retrieval(state[\"user_query\"], state[\"retrieved_docs\"])\n",
    "        # Extract confidence score from evaluation\n",
    "        confidence_score = 0.8 if \"Useful: True\" in evaluation_result else 0.3\n",
    "    \n",
    "    print(f\"Evaluation complete. Confidence: {confidence_score}\")\n",
    "    return {\n",
    "        \"evaluation_result\": evaluation_result,\n",
    "        \"confidence_score\": confidence_score\n",
    "    }\n",
    "\n",
    "def should_search_web(state: GameResearchState) -> str:\n",
    "    \"\"\"Decision point: Should we search the web?\"\"\"\n",
    "    return \"web_search\" if state[\"confidence_score\"] < 0.7 else \"generate_answer\"\n",
    "\n",
    "def search_web_step(state: GameResearchState) -> Dict:\n",
    "    \"\"\"Step 3: Search the web if needed\"\"\"\n",
    "    print(\"Searching the web for additional information...\")\n",
    "    \n",
    "    web_result = web_search(state[\"user_query\"])\n",
    "    sources_used = state.get(\"sources_used\", []) + [\"web_search\"]\n",
    "    confidence_score = min(state[\"confidence_score\"] + 0.4, 1.0)\n",
    "    \n",
    "    print(\"Web search complete\")\n",
    "    return {\n",
    "        \"web_search_result\": str(web_result),\n",
    "        \"sources_used\": sources_used,\n",
    "        \"confidence_score\": confidence_score\n",
    "    }\n",
    "\n",
    "def generate_final_answer(state: GameResearchState) -> Dict:\n",
    "    \"\"\"Step 4: Generate comprehensive final answer\"\"\"\n",
    "    print(\"Generating my final answer...\")\n",
    "    \n",
    "    # Create a comprehensive prompt for the LLM\n",
    "    context_parts = []\n",
    "    \n",
    "    if state[\"retrieved_docs\"] and state[\"retrieved_docs\"] != \"No games found matching your query.\":\n",
    "        context_parts.append(f\"Vector Database Results:\\n{state['retrieved_docs']}\")\n",
    "    \n",
    "    if state.get(\"web_search_result\"):\n",
    "        context_parts.append(f\"Web Search Results:\\n{state['web_search_result']}\")\n",
    "    \n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    final_prompt = f\"\"\"\n",
    "    Based on the following information, provide a answer to the user's question: \"{state['user_query']}\"\n",
    "\n",
    "    Available Information:\n",
    "    {context}\n",
    "\n",
    "    Please provide a well structured answer that answers the users question directly, if you could not find the answer explain why.\n",
    "\n",
    "    Sources used: {', '.join(state.get('sources_used', []))}\n",
    "    Confidence level: {state['confidence_score']}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use the LLM to generate the final answer\n",
    "    llm = LLM(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an expert game advisor working at our game store. Provide comprehensive, accurate information about video games.\"),\n",
    "        UserMessage(content=final_prompt)\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    print(\"Final answer generated\")\n",
    "    return {\"final_answer\": response.content}\n",
    "\n",
    "# Create the StateMachine using the actual API\n",
    "game_research_sm = StateMachine(GameResearchState)\n",
    "\n",
    "# Add all steps\n",
    "entry_step = EntryPoint()\n",
    "query_step = Step(\"query_db\", query_vector_db)\n",
    "evaluate_step = Step(\"evaluate\", evaluate_documents)\n",
    "web_search_step = Step(\"web_search\", search_web_step)\n",
    "answer_step = Step(\"generate_answer\", generate_final_answer)\n",
    "termination_step = Termination()\n",
    "\n",
    "game_research_sm.add_steps([\n",
    "    entry_step,\n",
    "    query_step,\n",
    "    evaluate_step,\n",
    "    web_search_step,\n",
    "    answer_step,\n",
    "    termination_step\n",
    "])\n",
    "\n",
    "# Connect the steps\n",
    "game_research_sm.connect(entry_step, query_step)\n",
    "game_research_sm.connect(query_step, evaluate_step)\n",
    "game_research_sm.connect(evaluate_step, [web_search_step, answer_step], condition=should_search_web)\n",
    "game_research_sm.connect(web_search_step, answer_step)\n",
    "game_research_sm.connect(answer_step, termination_step)\n",
    "\n",
    "print(\"✅ StateMachine created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d2c896a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STarting StateMachine Agent\n",
      "\n",
      "Query 1: When were Pokémon Gold and Silver released?\n",
      "[StateMachine] Starting: __entry__\n",
      "Searcing my database for information about the question :)\n",
      "Found documents\n",
      "[StateMachine] Executing step: query_db\n",
      " EValuating the quality of the answer from the db. Hope its GOOD\n",
      "Evaluation complete. Confidence: 0.8\n",
      "[StateMachine] Executing step: evaluate\n",
      "Generating my final answer...\n",
      "Final answer generated\n",
      "[StateMachine] Executing step: generate_answer\n",
      "[StateMachine] Terminating: __termination__\n",
      "Final Answer:\n",
      "Pokémon Gold and Silver were released in 1999 for the Game Boy Color. These games are notable for being the second generation of Pokémon games, introducing new regions, Pokémon, and gameplay mechanics. If you have any more questions about Pokémon or other games, feel free to ask!\n",
      "Sources used: vector_database\n",
      "Confidence: 80.0%\n",
      "\n",
      "Query 2: Which one was the first 3D platformer Mario game?\n",
      "[StateMachine] Starting: __entry__\n",
      "Searcing my database for information about the question :)\n",
      "Found documents\n",
      "[StateMachine] Executing step: query_db\n",
      " EValuating the quality of the answer from the db. Hope its GOOD\n",
      "Evaluation complete. Confidence: 0.8\n",
      "[StateMachine] Executing step: evaluate\n",
      "Generating my final answer...\n",
      "Final answer generated\n",
      "[StateMachine] Executing step: generate_answer\n",
      "[StateMachine] Terminating: __termination__\n",
      "Final Answer:\n",
      "The first 3D platformer Mario game is **Super Mario 64**, which was released in **1996** for the **Nintendo 64**. This game was groundbreaking and set new standards for the platforming genre, featuring Mario's quest to rescue Princess Peach. It introduced players to a fully realized 3D environment, allowing for new gameplay mechanics and exploration that were not possible in previous 2D Mario games. \n",
      "\n",
      "If you have any more questions about Mario games or other titles, feel free to ask!\n",
      "Sources used: vector_database\n",
      "Confidence: 80.0%\n",
      "\n",
      "Query 3: Was Mortal Kombat X released for PlayStation 5?\n",
      "[StateMachine] Starting: __entry__\n",
      "Searcing my database for information about the question :)\n",
      "Found documents\n",
      "[StateMachine] Executing step: query_db\n",
      " EValuating the quality of the answer from the db. Hope its GOOD\n",
      "Evaluation complete. Confidence: 0.3\n",
      "[StateMachine] Executing step: evaluate\n",
      "Searching the web for additional information...\n",
      "Web search complete\n",
      "[StateMachine] Executing step: web_search\n",
      "Generating my final answer...\n",
      "Final answer generated\n",
      "[StateMachine] Executing step: generate_answer\n",
      "[StateMachine] Terminating: __termination__\n",
      "Final Answer:\n",
      "Mortal Kombat X was not released as a standalone title for the PlayStation 5. It was originally launched for the PlayStation 4 in 2015. However, it is backward compatible on the PlayStation 5, meaning you can play the PlayStation 4 version of the game on your PS5 console. There is no specific PS5 version of Mortal Kombat X available. \n",
      "\n",
      "If you're interested in playing it on PS5, you can do so by using the PS4 version, which should run smoothly on the newer hardware.\n",
      "Sources used: vector_database, web_search\n",
      "Confidence: 70.0%\n"
     ]
    }
   ],
   "source": [
    "# Test queries for the workflow appraoch here is the final answer for all the questions\n",
    "\n",
    "test_queries = [\n",
    "    \"When were Pokémon Gold and Silver released?\",\n",
    "    \"Which one was the first 3D platformer Mario game?\",\n",
    "    \"Was Mortal Kombat X released for PlayStation 5?\"\n",
    "]\n",
    "\n",
    "print(\"STarting StateMachine Agent\")\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\nQuery {i}: {query}\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize state for StateMachine\n",
    "        initial_state = GameResearchState(\n",
    "            user_query=query,\n",
    "            retrieved_docs=\"\",\n",
    "            evaluation_result=\"\",\n",
    "            web_search_result=\"\",\n",
    "            final_answer=\"\",\n",
    "            confidence_score=0.0,\n",
    "            sources_used=[]\n",
    "        )\n",
    "        \n",
    "        # Run the StateMachine workflow\n",
    "        run_result = game_research_sm.run(initial_state)\n",
    "        final_state = run_result.get_final_state()\n",
    "        \n",
    "        print(f\"Final Answer:\")\n",
    "        print(f\"{final_state['final_answer']}\")\n",
    "        print(f\"Sources used: {', '.join(final_state['sources_used'])}\")\n",
    "        print(f\"Confidence: {final_state['confidence_score']:.1%}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5485694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so it works well and so sad that they did not released Mortal Kombat X for PS5 :(( But at least it works.\n",
    "# Thanks for this project was super nice serving as a beta tester :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update your agent with long-term memory\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes\n",
    "\n",
    "\n",
    "# since timing for beta testing is really tught, i will do this after submittingh my other projects promise!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
